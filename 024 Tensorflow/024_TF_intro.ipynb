{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cff2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ac4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes):\n",
    "    inputShape = (height, width, depth) # входной размер\n",
    "    chanDim = -1\n",
    "    model = Sequential([ # собираем последовательную модель\n",
    "        \n",
    "        # конволюционные слои\n",
    "        Conv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "        Activation(\"relu\"),\n",
    "        BatchNormalization(axis=chanDim),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "         # конволюционные слои\n",
    "        Conv2D(32, (3, 3), padding=\"same\"),\n",
    "        Activation(\"relu\"),\n",
    "        BatchNormalization(axis=chanDim),\n",
    "        Conv2D(32, (3, 3), padding=\"same\"),\n",
    "        Activation(\"relu\"),\n",
    "        BatchNormalization(axis=chanDim),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "         # полносвязные слои\n",
    "        Flatten(),\n",
    "        Dense(256),\n",
    "        Activation(\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(classes),\n",
    "        Activation(\"softmax\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691e872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(X, y):\n",
    "    # Функция для реализации обучения\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(X) # делаем предсказание\n",
    "        loss = categorical_crossentropy(y, pred) # вычисляем функцию ошибок\n",
    "    # calculate the gradients using our tape and then update the\n",
    "    # model weights\n",
    "    grads = tape.gradient(loss, model.trainable_variables) # расчитываем градиенты обратным распространением\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables)) # обновляем веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79ec4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, batch size, and\n",
    "# initial learning rate\n",
    "EPOCHS = 5 # кол-во эпох\n",
    "BS = 64 # размер батча\n",
    "INIT_LR = 1e-3 # скорость обчучения\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data() # загружаем данные\n",
    "\n",
    "# приводим к виду для подачи в модель\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "trainY = to_categorical(trainY, 10) # целевые признаки из категориальных в численные\n",
    "testY = to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7d17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    }
   ],
   "source": [
    "model = build_model(28, 28, 1, 10) # строим модель\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS) # создаем оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c995c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1/5...took 1.163 minutes\n",
      "[INFO] starting epoch 2/5...took 1.437 minutes\n",
      "[INFO] starting epoch 3/5...took 1.242 minutes\n",
      "[INFO] starting epoch 4/5...took 1.275 minutes\n",
      "[INFO] starting epoch 5/5...took 1.3 minutes\n"
     ]
    }
   ],
   "source": [
    "numUpdates = int(trainX.shape[0] / BS) # кол-во обновления парамтров за эпоху\n",
    "\n",
    "for epoch in range(0, EPOCHS): # итерируемся по всем эпохам\n",
    "    print(\"starting epoch {}/{}...\".format(\n",
    "        epoch + 1, EPOCHS), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    epochStart = time.time()\n",
    "    for i in range(0, numUpdates):\n",
    "        # определяем начальный и конечный индексы\n",
    "        start = i * BS\n",
    "        end = start + BS\n",
    "        step(trainX[start:end], trainY[start:end]) # делаем шаг обучения\n",
    "    epochEnd = time.time()\n",
    "    elapsed = (epochEnd - epochStart) / 60.0 # время на эпоху\n",
    "    print(\"took {:.4} minutes\".format(elapsed)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e7606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0376 - acc: 0.9886\n",
      "[INFO] test accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "# in order to calculate accuracy using Keras' functions we first need\n",
    "# to compile the model\n",
    "model.compile(optimizer=opt, loss=categorical_crossentropy, metrics=[\"acc\"]) # компилируем для расчета точности с использованием Keras \n",
    "\n",
    "(loss, acc) = model.evaluate(testX, testY) # считаем точность модели\n",
    "print(\"[INFO] test accuracy: {:.4f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
